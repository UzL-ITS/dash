{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44f84402-336a-4fb3-b73e-4b0f340252d7",
   "metadata": {},
   "source": [
    "# Evaluation of ReDash\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697843ab-e2e8-497a-b477-8df782fc4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "import tol_colors as tc\n",
    "plt.rc('axes', prop_cycle=plt.cycler('color', list(tc.tol_cset('bright'))))\n",
    "plt.cm.register_cmap('iridescent', tc.tol_cmap('iridescent'))\n",
    "plt.rc('image', cmap='iridescent')\n",
    "\n",
    "# Use the following for all plots except for runtime distribution plots\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 17,\n",
    "    \"font.size\": 16,  # same size as ticks label\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"xtick.labelsize\": 15,\n",
    "    \"ytick.labelsize\": 15,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"axes.titlesize\": 17\n",
    "}\n",
    "\n",
    "plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e584ddc5-dca4-4ed4-b2a6-4f46d7cfcee0",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ca828-0fb2-40a3-b6e7-61ce0a5fdd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_file(path, suffix):\n",
    "    paths = sorted(Path(path).iterdir(), key=os.path.getmtime, reverse=True)\n",
    "    paths = [str(p) for p in paths]\n",
    "    for p in paths:\n",
    "        if p.endswith(suffix):\n",
    "            return p\n",
    "\n",
    "def relative_std(x):\n",
    "  # https://github.com/pandas-dev/pandas/issues/33517\n",
    "  if not isinstance(x, pd.Series):\n",
    "        raise TypeError\n",
    "  \n",
    "  return np.nanstd(x)/np.nanmean(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34feceb2-8ccf-4153-b7d2-f2a60845ec1b",
   "metadata": {},
   "source": [
    "## Micro-Benchmarks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3df0a271",
   "metadata": {},
   "source": [
    "#### Rescaling old vs new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb38bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaling = get_latest_file(\"micro_benchmarks/data\", \"_rescaling.csv\")\n",
    "print(rescaling)\n",
    "\n",
    "\n",
    "rescaling_data = pd.read_csv(rescaling, skipinitialspace=True)\n",
    "rescaling_data = rescaling_data.drop(columns=[\"run\", \"crt_base_size\", \"gpu_mem_usage\"])\n",
    "rescaling_data = rescaling_data.groupby([\"dimensions\", \"type\", \"use_legacy_scaling\"]).aggregate(['mean', 'std', relative_std])\n",
    "rescaling_data = rescaling_data.unstack([-1])\n",
    "rescaling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024da4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "mean_cpu = rescaling_data[\"runtime\"][\"mean\"].xs(\"CPU\", level=\"type\")\n",
    "std_cpu = rescaling_data[\"runtime\"][\"std\"].xs(\"CPU\", level=\"type\")\n",
    "\n",
    "mean_cpu.plot(kind=\"bar\", ax=ax, yerr=std_cpu, capsize=4)\n",
    "ax.set_xlabel(\"Inputs\")\n",
    "ax.set_ylabel(\"Runtime (ms)\")\n",
    "ax.set_xticklabels(mean_cpu.index, rotation=45)\n",
    "\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, ['New Scaling', 'Legacy Scaling'])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"micro_benchmarks/data/rescaling_runtime.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61358750-b216-4161-bced-f4f0eea7ac6b",
   "metadata": {},
   "source": [
    "### CPU-Scalability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "972dbe12",
   "metadata": {},
   "source": [
    "#### Rescaling (1-16 Threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5591ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rescaling_scale = get_latest_file(\"micro_benchmarks/data/scalability\", \"_rescaling.csv\")\n",
    "print(path_rescaling_scale)\n",
    "\n",
    "rescaling_scale_data = pd.read_csv(path_rescaling_scale, skipinitialspace=True)\n",
    "rescaling_scale_data = rescaling_scale_data.drop(columns=[\"run\", \"crt_base_size\", \"type\"])\n",
    "rescaling_scale_data = rescaling_scale_data.groupby([\"dims\", \"nr_threads\", 'l']).aggregate(['mean', 'std', relative_std])\n",
    "rescaling_scale_data = rescaling_scale_data.unstack([-2])\n",
    "rescaling_scale_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rescaling_scale_MORE_INPUT_SIZES = get_latest_file(\"micro_benchmarks/data/scalability\", \"_rescaling_more_inputs.csv\")\n",
    "print(path_rescaling_scale_MORE_INPUT_SIZES)\n",
    "\n",
    "rescaling_scale_data_MORE_INPUT_SIZES = pd.read_csv(path_rescaling_scale_MORE_INPUT_SIZES, skipinitialspace=True)\n",
    "rescaling_scale_data_MORE_INPUT_SIZES = rescaling_scale_data_MORE_INPUT_SIZES.drop(columns=[\"run\", \"crt_base_size\", \"type\"])\n",
    "rescaling_scale_data_MORE_INPUT_SIZES = rescaling_scale_data_MORE_INPUT_SIZES.groupby([\"dims\", \"nr_threads\", 'l']).aggregate(['mean', 'std', relative_std])\n",
    "rescaling_scale_data_MORE_INPUT_SIZES = rescaling_scale_data_MORE_INPUT_SIZES.unstack([-2])\n",
    "rescaling_scale_data_MORE_INPUT_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bccf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rescaling_scale_DASH = get_latest_file(\"micro_benchmarks/data/scalability\", \"IMPORTED_DASH_RESCALING_SCALABILITY.csv\")\n",
    "print(path_rescaling_scale_DASH)\n",
    "\n",
    "rescaling_scale_data_DASH = pd.read_csv(path_rescaling_scale_DASH, skipinitialspace=True)\n",
    "rescaling_scale_data_DASH = rescaling_scale_data_DASH.drop(columns=[\"run\", \"crt_base_size\", \"type\"])\n",
    "rescaling_scale_data_DASH = rescaling_scale_data_DASH.groupby([\"dims\", \"nr_threads\", 'l']).aggregate(['mean', 'std', relative_std])\n",
    "rescaling_scale_data_DASH = rescaling_scale_data_DASH.unstack([-2])\n",
    "rescaling_scale_data_DASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda464e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rescaling_scale_DASH_MORE_INPUT_SIZES = get_latest_file(\"micro_benchmarks/data/scalability\", \"IMPORTED_DASH_RESCALING_SCALABILITY_MORE_INPUT_SIZES.csv\")\n",
    "print(path_rescaling_scale_DASH_MORE_INPUT_SIZES)\n",
    "\n",
    "rescaling_scale_data_DASH_MORE_INPUT_SIZES = pd.read_csv(path_rescaling_scale_DASH_MORE_INPUT_SIZES, skipinitialspace=True)\n",
    "rescaling_scale_data_DASH_MORE_INPUT_SIZES = rescaling_scale_data_DASH_MORE_INPUT_SIZES.drop(columns=[\"run\", \"crt_base_size\", \"type\"])\n",
    "rescaling_scale_data_DASH_MORE_INPUT_SIZES = rescaling_scale_data_DASH_MORE_INPUT_SIZES.groupby([\"dims\", \"nr_threads\", 'l']).aggregate(['mean', 'std', relative_std])\n",
    "rescaling_scale_data_DASH_MORE_INPUT_SIZES = rescaling_scale_data_DASH_MORE_INPUT_SIZES.unstack([-2])\n",
    "rescaling_scale_data_DASH_MORE_INPUT_SIZES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec1454a3-fb8b-4068-b8f1-0582290da87b",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366062",
   "metadata": {},
   "source": [
    "#### Rescaling (threads, input sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5653b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the common dims values between legacy and DASH datasets and keep only the first two\n",
    "dims_common = sorted(set(rescaling_scale_data.index.get_level_values('dims')).intersection(\n",
    "                       set(rescaling_scale_data_DASH.index.get_level_values('dims'))))[:1]\n",
    "\n",
    "# Colors for ℓ=3 and ℓ=5.\n",
    "color_l3 = \"tab:blue\"\n",
    "color_l5 = \"tab:orange\"\n",
    "\n",
    "# =====================\n",
    "# LEFT SUBPLOT: Scaling Curves (line plots with error bars)\n",
    "# =====================\n",
    "# Assume dims_common is defined; here we pick the first dimension.\n",
    "d = dims_common[0]  # adjust as needed\n",
    "\n",
    "# Prepare the left axis\n",
    "fig, (ax_left, ax_right) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "# Plot ReDASH scaling curves for ℓ=3 and ℓ=5.\n",
    "for l in [3, 5]:\n",
    "    data = rescaling_scale_data.loc[(d, l)]\n",
    "    runtime_mean = data['runtime']['mean']\n",
    "    runtime_std = data['runtime']['std']\n",
    "    threads = runtime_mean.index.astype(int)\n",
    "    color = color_l3 if l == 3 else color_l5\n",
    "    ax_left.errorbar(threads, runtime_mean, yerr=runtime_std, marker='o', linestyle='-', \n",
    "                     color=color, capsize=4, label=f\"ReDASH, $\\\\ell={l}$\")\n",
    "    \n",
    "# Plot DASH scaling curves for ℓ=3 and ℓ=5.\n",
    "for l in [3, 5]:\n",
    "    data = rescaling_scale_data_DASH.loc[(d, l)]\n",
    "    runtime_mean = data['runtime']['mean']\n",
    "    runtime_std = data['runtime']['std']\n",
    "    threads = runtime_mean.index.astype(int)\n",
    "    color = color_l3 if l == 3 else color_l5\n",
    "    ax_left.errorbar(threads, runtime_mean, yerr=runtime_std, marker='*', linestyle='--', \n",
    "                     color=color, capsize=4, label=f\"DASH, $\\\\ell={l}$\")\n",
    "    \n",
    "ax_left.set_xlabel(\"Thread Count\")\n",
    "ax_left.set_xticks(np.arange(1, 17))\n",
    "ax_left.set_ylabel(\"Runtime (ms)\")\n",
    "ax_left.grid(False)\n",
    "\n",
    "# =====================\n",
    "# RIGHT SUBPLOT: Input Runtime Comparison (line plots with error bars, equally spaced x-axis)\n",
    "# =====================\n",
    "# Extract runtime means and standard deviations for 16 threads from both datasets.\n",
    "redash_runtime = rescaling_scale_data_MORE_INPUT_SIZES[\"runtime\"][\"mean\"].loc[:, 16]\n",
    "redash_std     = rescaling_scale_data_MORE_INPUT_SIZES[\"runtime\"][\"std\"].loc[:, 16]\n",
    "dash_runtime   = rescaling_scale_data_DASH_MORE_INPUT_SIZES[\"runtime\"][\"mean\"].loc[:, 16]# TODO: dash data here\n",
    "dash_std       = rescaling_scale_data_DASH_MORE_INPUT_SIZES[\"runtime\"][\"std\"].loc[:, 16] # TODO: dash data here\n",
    "\n",
    "# Define the input counts and the ℓ values of interest.\n",
    "inputs = [128, 256, 1024, 2048, 4096, 8192, 16384]\n",
    "l_values = [3, 5]\n",
    "\n",
    "# Create positions for the groups that are equally spaced.\n",
    "positions = np.arange(len(inputs))\n",
    "\n",
    "# Extract the corresponding runtime means and stds.\n",
    "redash_l3     = redash_runtime.loc[inputs, l_values[0]]\n",
    "redash_l3_std = redash_std.loc[inputs, l_values[0]]\n",
    "redash_l5     = redash_runtime.loc[inputs, l_values[1]]\n",
    "redash_l5_std = redash_std.loc[inputs, l_values[1]]\n",
    "dash_l3       = dash_runtime.loc[inputs, l_values[0]]\n",
    "dash_l3_std   = dash_std.loc[inputs, l_values[0]]\n",
    "dash_l5       = dash_runtime.loc[inputs, l_values[1]]\n",
    "dash_l5_std   = dash_std.loc[inputs, l_values[1]]\n",
    "\n",
    "# Plot as line plots with error bars using the new equally spaced positions.\n",
    "ax_right.errorbar(positions, redash_l3, yerr=redash_l3_std, marker='o', linestyle='-', \n",
    "                    color=color_l3, capsize=4, label=\"ReDASH, $\\\\ell=3$\")\n",
    "ax_right.errorbar(positions, redash_l5, yerr=redash_l5_std, marker='o', linestyle='-', \n",
    "                    color=color_l5, capsize=4, label=\"ReDASH, $\\\\ell=5$\")\n",
    "ax_right.errorbar(positions, dash_l3, yerr=dash_l3_std, marker='o', linestyle='--', \n",
    "                    color=color_l3, capsize=4, label=\"DASH, $\\\\ell=3$\")\n",
    "ax_right.errorbar(positions, dash_l5, yerr=dash_l5_std, marker='o', linestyle='--', \n",
    "                    color=color_l5, capsize=4, label=\"DASH, $\\\\ell=5$\")\n",
    "\n",
    "ax_right.set_xlabel(\"Number of Inputs\")\n",
    "ax_right.set_ylabel(\"Runtime (ms)\")\n",
    "ax_right.set_xticks(positions)\n",
    "ax_right.set_xticklabels(inputs)\n",
    "# ax_right.set_yscale('log')\n",
    "ax_right.grid(False)\n",
    "\n",
    "# =====================\n",
    "# Shared Legend\n",
    "# =====================\n",
    "# Collect handles and labels from both axes.\n",
    "handles_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "handles_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "all_handles = handles_left + handles_right\n",
    "all_labels = labels_left + labels_right\n",
    "\n",
    "# Remove duplicates while preserving order.\n",
    "unique = {}\n",
    "for handle, label in zip(all_handles, all_labels):\n",
    "    if label not in unique:\n",
    "        unique[label] = handle\n",
    "\n",
    "fig.legend(unique.values(), unique.keys(), loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.02))\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "# plt.show()\n",
    "\n",
    "# Optionally, save the merged plot.\n",
    "fig.savefig(\"micro_benchmarks/data/merged_runtime_comparison.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b12178e4-bf32-481a-92ff-a2825ee973b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b7cab-a4ed-4c72-b54b-1e99d364dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = get_latest_file(\"model_benchmarks/data\", \"_garbled_models.csv\")\n",
    "# path_models = get_latest_file(\"model_benchmarks/data\", \"_sgx_models.csv\")\n",
    "print(path_models)\n",
    "models_data = pd.read_csv(path_models, skipinitialspace=True)\n",
    "models_data = models_data[models_data[\"relu_acc\"] == 100]\n",
    "models_data = models_data.drop(columns=[\"target_crt_base_size\", \"label\", \"infered_label\", \"relu_acc\", \"type\"])\n",
    "models_data = models_data.groupby([\"model\", \"optimize_bases\"]).aggregate(['mean', 'std', relative_std])\n",
    "models_data = models_data.unstack()\n",
    "models_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f287f699-dcb3-4cea-a714-b68b96237898",
   "metadata": {},
   "source": [
    "### Add available data of other frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e68ca-b34f-499d-a2ef-82cf9d4636d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index so that we can iterate through the numbers.\n",
    "# This will help us to get the x tick positions\n",
    "df = models_data[\"runtime\"][\"mean\"]\n",
    "df = df.reset_index() # Uncomment if you want to use the index as x ticks\n",
    "# Add data from gnn paper\n",
    "df[\"DASH (CPU)\"] = [10263, 23959]\n",
    "# df[\"DASH (GPU)\"] = [1332, 1443]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b702719b-151a-420b-8820-1cf115ef6fe8",
   "metadata": {},
   "source": [
    "### Comparison of Dash's model runtimes against other frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f13608-b530-4d7c-bf25-3cc88b689a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df for only models F (capital) and f (lowercase)\n",
    "df_filtered = df[df[\"model\"].isin([\"MODEL_F_GNNP_POOL_REPL\", \"MODEL_F_MINIONN_POOL_REPL\"])]\n",
    "\n",
    "# Create a 1x2 grid of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Get the runtime columns (excluding \"model\")\n",
    "runtime_columns = [col for col in df.columns if col != \"model\"]\n",
    "# Swap the first two columns so that the ReDASH bars are switched\n",
    "runtime_columns[0], runtime_columns[1] = runtime_columns[1], runtime_columns[0]\n",
    "runtime_labels = [(\"ReDASH w/ CPM-Bases (CPU)\" if col == 0 \n",
    "                   else \"ReDASH w/ Optimized Bases (CPU)\" if col == 1 \n",
    "                   else col) for col in runtime_columns]\n",
    "\n",
    "# Loop through each filtered model and plot its runtime bars\n",
    "for i, (idx, row) in enumerate(df_filtered.iterrows()):\n",
    "    ax_model = axs[i]\n",
    "    positions = list(range(len(runtime_columns)))\n",
    "    if 'color_hatch_combinations' not in globals():\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        hatches = ['', '//', '\\\\\\\\', '||', '--', '++', 'xx', 'oo', 'OO', '..', '**']\n",
    "        color_hatch_combinations = [(colors[i % (len(colors)-1)], h) for i, h in enumerate(hatches)]\n",
    "    for j, col in enumerate(runtime_columns):\n",
    "        c, h = color_hatch_combinations[j % len(color_hatch_combinations)]\n",
    "        ax_model.bar(positions[j], row[col], color=c, hatch=h, width=0.8)\n",
    "    ax_model.set_xticks(positions)\n",
    "    # Remove x-axis tick labels by not setting them:\n",
    "    ax_model.set_xticklabels([])\n",
    "    \n",
    "    # Remove the \"MODEL_\" prefix and then rename as needed\n",
    "    title = row[\"model\"].replace(\"MODEL_\", \"\")\n",
    "    if title == \"F_GNNP_POOL_REPL\":\n",
    "        title = \"f\"\n",
    "    elif title == \"F_MINIONN_POOL_REPL\":\n",
    "        title = \"F\"\n",
    "    ax_model.set_title(title)\n",
    "    ax_model.set_ylabel(\"Runtime (ms)\")\n",
    "\n",
    "# Create a single global legend using custom patches.\n",
    "import matplotlib.patches as mpatches\n",
    "legend_handles = []\n",
    "for j, col in enumerate(runtime_columns):\n",
    "    c, h = color_hatch_combinations[j % len(color_hatch_combinations)]\n",
    "    label = \"ReDASH w/ CPM-Bases (CPU)\" if col == 0 else (\"ReDASH w/ Optimized Bases (CPU)\" if col == 1 else col)\n",
    "    patch = mpatches.Patch(facecolor=c, hatch=h, label=label)\n",
    "    legend_handles.append(patch)\n",
    "\n",
    "# Place the global legend at the top center\n",
    "fig.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, 0.98), ncol=len(runtime_columns))\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "fig.savefig('model_benchmarks/data/models_runtime_comparison_subplots.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ee611",
   "metadata": {},
   "source": [
    "### Runtime Distribution over Layer-Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = get_latest_file(\"model_benchmarks/data\", \"IMPORTED_REDASH_RUNTIME_DISTRIBUTION_EVALUATION.csv\")\n",
    "print(path_models)\n",
    "runtime_dist_data = pd.read_csv(path_models, skipinitialspace=True)\n",
    "runtime_dist_data[runtime_dist_data[\"relu_acc\"] == 100]\n",
    "\n",
    "runtime_dist_data = runtime_dist_data.drop(columns=[\"target_crt_base_size\", \"relu_acc\", \"type\"])\n",
    "runtime_dist_data = runtime_dist_data.groupby([\"model\", \"layer\", \"optimize_bases\"]).aggregate(['mean', 'std', relative_std])\n",
    "\n",
    "# add 0 second entries for missing layers (not all models contain all layers)\n",
    "runtime_dist_data = runtime_dist_data.unstack(0)[\"runtime\"][\"mean\"]\n",
    "runtime_dist_data.fillna(0, inplace=True)\n",
    "runtime_dist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f27d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = get_latest_file(\"model_benchmarks/data\", \"IMPORTED_DASH_RUNTIME_DISTRIBUTION_EVALUATION.csv\")\n",
    "print(path_models)\n",
    "runtime_dist_data_DASH = pd.read_csv(path_models, skipinitialspace=True)\n",
    "\n",
    "# Only keep rows with relu_acc==100 and where \"type\" is not \"GPU\"\n",
    "runtime_dist_data_DASH = runtime_dist_data_DASH[(runtime_dist_data_DASH[\"relu_acc\"] == 100) & (runtime_dist_data_DASH[\"type\"] != \"GPU\")]\n",
    "\n",
    "runtime_dist_data_DASH = runtime_dist_data_DASH.drop(columns=[\"target_crt_base_size\", \"relu_acc\", \"type\"])\n",
    "runtime_dist_data_DASH = runtime_dist_data_DASH.groupby([\"model\", \"layer\"]).aggregate(['mean', 'std', relative_std])\n",
    "\n",
    "# Add 0 second entries for missing layers (not all models contain all layers)\n",
    "runtime_dist_data_DASH = runtime_dist_data_DASH.unstack(0)[\"runtime\"][\"mean\"]\n",
    "runtime_dist_data_DASH.fillna(0, inplace=True)\n",
    "runtime_dist_data_DASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTED_EIGEN_runtime_distribution_evaluation.csv\n",
    "path_eigen = get_latest_file(\"model_benchmarks/data\", \"IMPORTED_EIGEN_runtime_distribution_evaluation.csv\")\n",
    "print(path_eigen)\n",
    "runtime_dist_data_EIGEN = pd.read_csv(path_eigen, skipinitialspace=True)\n",
    "runtime_dist_data_EIGEN = runtime_dist_data_EIGEN[(runtime_dist_data_EIGEN[\"relu_acc\"] == 100) &\n",
    "                                                  (runtime_dist_data_EIGEN[\"type\"] != \"GPU\")]\n",
    "runtime_dist_data_EIGEN = runtime_dist_data_EIGEN.drop(columns=[\"target_crt_base_size\", \"relu_acc\", \"type\"])\n",
    "runtime_dist_data_EIGEN = runtime_dist_data_EIGEN.groupby([\"model\", \"layer\"]).aggregate(['mean', 'std', relative_std])\n",
    "runtime_dist_data_EIGEN = runtime_dist_data_EIGEN.unstack(0)[\"runtime\"][\"mean\"]\n",
    "runtime_dist_data_EIGEN.fillna(0, inplace=True)\n",
    "runtime_dist_data_EIGEN\n",
    "\n",
    "# IMPORTED_INT32_EIGEN_runtime_distribution_evaluation.csv\n",
    "path_int32_eigen = get_latest_file(\"model_benchmarks/data\", \"IMPORTED_INT32_EIGEN_runtime_distribution_evaluation.csv\")\n",
    "print(path_int32_eigen)\n",
    "runtime_dist_data_INT32_EIGEN = pd.read_csv(path_int32_eigen, skipinitialspace=True)\n",
    "runtime_dist_data_INT32_EIGEN = runtime_dist_data_INT32_EIGEN[(runtime_dist_data_INT32_EIGEN[\"relu_acc\"] == 100) &\n",
    "                                                              (runtime_dist_data_INT32_EIGEN[\"type\"] != \"GPU\")]\n",
    "runtime_dist_data_INT32_EIGEN = runtime_dist_data_INT32_EIGEN.drop(columns=[\"target_crt_base_size\", \"relu_acc\", \"type\"])\n",
    "runtime_dist_data_INT32_EIGEN = runtime_dist_data_INT32_EIGEN.groupby([\"model\", \"layer\"]).aggregate(['mean', 'std', relative_std])\n",
    "runtime_dist_data_INT32_EIGEN = runtime_dist_data_INT32_EIGEN.unstack(0)[\"runtime\"][\"mean\"]\n",
    "runtime_dist_data_INT32_EIGEN.fillna(0, inplace=True)\n",
    "runtime_dist_data_INT32_EIGEN\n",
    "\n",
    "# IMPORTED_INT32_NOEIGEN_runtime_distribution_evaluation.csv\n",
    "path_int32_noeigen = get_latest_file(\"model_benchmarks/data\", \"IMPORTED_INT32_NOEIGEN_runtime_distribution_evaluation.csv\")\n",
    "print(path_int32_noeigen)\n",
    "runtime_dist_data_INT32_NOEIGEN = pd.read_csv(path_int32_noeigen, skipinitialspace=True)\n",
    "runtime_dist_data_INT32_NOEIGEN = runtime_dist_data_INT32_NOEIGEN[(runtime_dist_data_INT32_NOEIGEN[\"relu_acc\"] == 100) &\n",
    "                                                                  (runtime_dist_data_INT32_NOEIGEN[\"type\"] != \"GPU\")]\n",
    "runtime_dist_data_INT32_NOEIGEN = runtime_dist_data_INT32_NOEIGEN.drop(columns=[\"target_crt_base_size\", \"relu_acc\", \"type\"])\n",
    "runtime_dist_data_INT32_NOEIGEN = runtime_dist_data_INT32_NOEIGEN.groupby([\"model\", \"layer\"]).aggregate(['mean', 'std', relative_std])\n",
    "runtime_dist_data_INT32_NOEIGEN = runtime_dist_data_INT32_NOEIGEN.unstack(0)[\"runtime\"][\"mean\"]\n",
    "runtime_dist_data_INT32_NOEIGEN.fillna(0, inplace=True)\n",
    "runtime_dist_data_INT32_NOEIGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the two models corresponding to f and F.\n",
    "model_names = [\"MODEL_F_GNNP_POOL_REPL\", \"MODEL_F_MINIONN_POOL_REPL\"]\n",
    "\n",
    "# For runtime_dist_data, the index is multi-index (layer, optimize_bases).\n",
    "# Sum over optimize_bases so that each layer gets a single value per model.\n",
    "df_redash = runtime_dist_data[model_names].groupby(level=0).sum()\n",
    "# For runtime_dist_data_DASH, the index is simply the layer.\n",
    "df_dash = runtime_dist_data_DASH[model_names]\n",
    "\n",
    "# Determine the layer order.\n",
    "# For ReDASH, note that the available layers are in the index of df_redash.\n",
    "layer_order_redash = list(df_redash.index)\n",
    "# For DASH, use the order as it appears (or force a consistent order if desired).\n",
    "layer_order_dash = list(df_dash.index)\n",
    "\n",
    "# Compute percentage contributions per layer for each model.\n",
    "def compute_percentages(df, models, layers):\n",
    "    # Create a dict: key=layer, value = list of percentages across models\n",
    "    data = {layer: [] for layer in layers}\n",
    "    for m in models:\n",
    "        total = df[m].sum()\n",
    "        for layer in layers:\n",
    "            pct = (df.loc[layer, m] / total * 100) if total!=0 else 0\n",
    "            data[layer].append(pct)\n",
    "    return data\n",
    "\n",
    "redash_percent = compute_percentages(df_redash, model_names, layer_order_redash)\n",
    "dash_percent = compute_percentages(df_dash, model_names, layer_order_dash)\n",
    "\n",
    "# Set up colors and hatches.\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "hatches = ['', '//', '\\\\\\\\', '||', '--', '++', 'xx', 'oo', 'OO', '..', '**']\n",
    "color_hatch_combinations = [(colors[i % (len(colors)-1)], hatches[i % len(hatches)]) for i in range(max(len(layer_order_redash), len(layer_order_dash)))]\n",
    "\n",
    "# Create subplots: left for ReDASH, right for DASH.\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3), sharey=True)\n",
    "fig.tight_layout(pad=3)\n",
    "\n",
    "# For both axes, the y-axis corresponds to the two models.\n",
    "y_positions = range(len(model_names))\n",
    "\n",
    "# Plot for ReDASH.\n",
    "left = [0, 0]  # starting left position for each model bar (two models)\n",
    "for idx, layer in enumerate(layer_order_redash):\n",
    "    c, h = color_hatch_combinations[idx]\n",
    "    axs[0].barh(model_names, redash_percent[layer], left=left, label=layer, color=c, hatch=h)\n",
    "    left = [l + v for l, v in zip(left, redash_percent[layer])]\n",
    "axs[0].set_title(\"ReDASH\")\n",
    "axs[0].set_xlabel(\"Runtime share (\\%)\")\n",
    "axs[0].set_ylabel(\"Model\")\n",
    "\n",
    "# Plot for DASH.\n",
    "left_dash = [0, 0]\n",
    "for idx, layer in enumerate(layer_order_dash):\n",
    "    c, h = color_hatch_combinations[idx]\n",
    "    axs[1].barh(model_names, dash_percent[layer], left=left_dash, label=layer, color=c, hatch=h)\n",
    "    left_dash = [l + v for l, v in zip(left_dash, dash_percent[layer])]\n",
    "axs[1].set_title(\"DASH\")\n",
    "axs[1].set_xlabel(\"Runtime share (\\%)\")\n",
    "\n",
    "# Create a combined legend (using those from the left subplot).\n",
    "# Here we combine the labels from both plots; the order is taken from layer_order_redash.\n",
    "all_handles = []\n",
    "for idx, layer in enumerate(layer_order_redash):\n",
    "    c, h = color_hatch_combinations[idx]\n",
    "    patch = plt.matplotlib.patches.Patch(facecolor=c, hatch=h, label=layer)\n",
    "    all_handles.append(patch)\n",
    "fig.legend(handles=all_handles, loc='upper center', ncol=len(layer_order_redash), bbox_to_anchor=(0.5, 1.1))\n",
    "\n",
    "fig.savefig(\"model_benchmarks/data/runtime_distribution_Fmodels.pdf\", format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfe05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute total runtime contributions per layer for each model.\n",
    "def compute_totals(df, models, layers):\n",
    "    # Returns a dict: key=layer, value = list of total runtimes per model\n",
    "    data = {layer: [] for layer in layers}\n",
    "    for m in models:\n",
    "        for layer in layers:\n",
    "            # If a layer is missing in the dataframe, use 0.\n",
    "            val = df.loc[layer, m] if layer in df.index else 0\n",
    "            data[layer].append(val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90330b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "df_redash_optim = runtime_dist_data[model_names].xs(1, level=\"optimize_bases\")\n",
    "df_redash_cpm   = runtime_dist_data[model_names].xs(0, level=\"optimize_bases\")\n",
    "df_dash         = runtime_dist_data_DASH[model_names]  # already has a single index: layer\n",
    "\n",
    "# Determine layer order for each dataset.\n",
    "# For ReDASH use the union of layers from the two optimize_bases values\n",
    "layer_order_redash = sorted(set(df_redash_optim.index).union(df_redash_cpm.index))\n",
    "layer_order_dash   = list(df_dash.index)\n",
    "\n",
    "# Use the union order for plotting across datasets\n",
    "layers = layer_order_redash\n",
    "\n",
    "# Compute total runtime values instead of percentages.\n",
    "redash_optim_total = compute_totals(df_redash_optim, model_names, layers)\n",
    "redash_cpm_total   = compute_totals(df_redash_cpm,   model_names, layers)\n",
    "dash_total         = compute_totals(df_dash,         model_names, layers)\n",
    "\n",
    "# print(redash_optim_total)\n",
    "# print(redash_cpm_total)\n",
    "# print(dash_total)\n",
    "\n",
    "# Update the cpm and dash totals for model f manually with values from ReDASH paper (manual fix for ArXiV version)\n",
    "# redash_cpm_total['approx_relu'][0] = 529.0\n",
    "# redash_cpm_total['conv2d'][0] = 5135.0\n",
    "# redash_cpm_total['dense'][0] = 0.5\n",
    "# redash_cpm_total['rescale'][0] = 437.0\n",
    "# dash_total['approx_relu'][0] = 538.0\n",
    "# dash_total['conv2d'][0] = 6771.0\n",
    "# dash_total['dense'][0] = 0.6\n",
    "# dash_total['rescale'][0] = 2841.0\n",
    "\n",
    "# Update the optim, cpm and dash totals for model F manually with values from ReDASH paper (manual fix for ArXiV version)\n",
    "# redash_optim_total['approx_relu'][1] = 433.0\n",
    "# redash_optim_total['conv2d'][1] = 2742.0\n",
    "# redash_optim_total['dense'][1] = 0.2\n",
    "# redash_optim_total['rescale'][1] = 455.0\n",
    "# redash_cpm_total['approx_relu'][1] = 982.0\n",
    "# redash_cpm_total['conv2d'][1] = 13393.0\n",
    "# redash_cpm_total['dense'][1] = 0.6\n",
    "# redash_cpm_total['rescale'][1] = 763.0\n",
    "# dash_total['approx_relu'][1] = 981.0\n",
    "# dash_total['conv2d'][1] = 17760.0\n",
    "# dash_total['dense'][1] = 0.6\n",
    "# dash_total['rescale'][1] = 5274.0\n",
    "\n",
    "print(redash_optim_total)\n",
    "print(redash_cpm_total)\n",
    "print(dash_total)\n",
    "\n",
    "# Define the three dataset categories to compare.\n",
    "datasets = [\"ReDASH Optimized\", \"ReDASH CPM\", \"DASH\"]\n",
    "n_datasets = len(datasets)\n",
    "n_models = len(model_names)\n",
    "bar_width = 0.25\n",
    "\n",
    "# x positions for model groups.\n",
    "indices = np.arange(n_models)\n",
    "\n",
    "# Create a mapping for layers to style using the pre-defined color_hatch_combinations.\n",
    "layer_style = {layer: color_hatch_combinations[i % len(color_hatch_combinations)]\n",
    "                for i, layer in enumerate(layers)}\n",
    "\n",
    "# Setup the figure.\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot bars for each dataset category.\n",
    "# Offsets: centered grouping per model.\n",
    "for i, dataset in enumerate(datasets):\n",
    "    pos = indices + (i - (n_datasets - 1) / 2) * bar_width\n",
    "    for j, m in enumerate(model_names):\n",
    "        if dataset == \"ReDASH Optimized\":\n",
    "            ser = pd.Series({layer: redash_optim_total.get(layer, [0]*n_models)[j] for layer in layers})\n",
    "        elif dataset == \"ReDASH CPM\":\n",
    "            ser = pd.Series({layer: redash_cpm_total.get(layer, [0]*n_models)[j] for layer in layers})\n",
    "        elif dataset == \"DASH\":\n",
    "            ser = pd.Series({layer: dash_total.get(layer, [0]*n_models)[j] for layer in layers})\n",
    "        bottom = 0\n",
    "        for layer in layers:\n",
    "            val = ser[layer]\n",
    "            c, h = layer_style[layer]\n",
    "            ax.bar(pos[j], val, bar_width, bottom=bottom, color=c, hatch=h, edgecolor='black')\n",
    "            bottom += val\n",
    "\n",
    "# Set x-axis: one tick per model (using the center of grouped bars)\n",
    "ax.set_xticks(indices)\n",
    "# Replace model names with short labels: f and F.\n",
    "model_labels = {\"MODEL_F_GNNP_POOL_REPL\": \"f\", \"MODEL_F_MINIONN_POOL_REPL\": \"F\"}\n",
    "# ax.set_xticklabels([model_labels[m] for m in model_names])\n",
    "# ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Online runtime (ms)\")\n",
    "\n",
    "# Instead of placing model labels at the default bottom,\n",
    "# we remove the current ticks and set two x-axis labels.\n",
    "# 1. Bottom ticks for dataset categories (I, II, III) for each model.\n",
    "roman = [\"I\", \"II\", \"III\"]\n",
    "tick_positions = []\n",
    "tick_labels = []\n",
    "for x in indices:\n",
    "    for i in range(n_datasets):\n",
    "        tick_positions.append(x + (i - (n_datasets - 1)/2)*bar_width)\n",
    "        tick_labels.append(roman[i])\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(tick_labels)\n",
    "ax.set_xlabel(\"Setup\")\n",
    "\n",
    "# 2. Create a twin x-axis at the top for the model labels (f and F).\n",
    "ax_top = ax.twiny()\n",
    "ax_top.set_xlim(ax.get_xlim())\n",
    "ax_top.set_xticks(indices)\n",
    "ax_top.set_xticklabels([model_labels[m] for m in model_names])\n",
    "ax_top.xaxis.set_ticks_position('top')\n",
    "ax_top.xaxis.set_label_position('top')\n",
    "ax_top.set_xlabel(\"Model\")\n",
    "ax_top.set_zorder(-1)\n",
    "\n",
    "layer_label = {\n",
    "    'approx_relu': 'ReLU',\n",
    "    'conv2d': 'Conv2d',\n",
    "    'dense': 'Dense',\n",
    "    'rescale': 'Scaling'\n",
    "}\n",
    "\n",
    "# Create a combined legend for layers.\n",
    "legend_handles = [mpatches.Patch(facecolor=layer_style[layer][0],\n",
    "                                 hatch=layer_style[layer][1],\n",
    "                                 edgecolor='black',\n",
    "                                 label=layer_label.get(layer, layer))\n",
    "                  for layer in layers]\n",
    "ax.legend(handles=legend_handles, title=\"Layer\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.tight_layout()\n",
    "ax.grid(False)\n",
    "\n",
    "# Optionally, save the figure:\n",
    "fig.savefig(\"model_benchmarks/data/vertical_combined_runtime_distribution.pdf\", format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db71a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"MODEL_F_GNNP_POOL_REPL\", \"MODEL_F_MINIONN_POOL_REPL\"]\n",
    "dataset_labels = [\"I\", \"I*\", \"I**\"]\n",
    "\n",
    "# Use the union of layers from the ReDASH optimized results.\n",
    "layers = sorted(df_redash_optim.index)  # e.g., ['approx_relu', 'conv2d', 'dense', 'rescale']\n",
    "\n",
    "# Compute total runtime values instead of percentages.\n",
    "redash_optim_total = compute_totals(df_redash_optim, model_names, layers)\n",
    "redash_eigen_total   = compute_totals(runtime_dist_data_EIGEN, model_names, layers)\n",
    "redash_int32_eigen_total         = compute_totals(runtime_dist_data_INT32_EIGEN, model_names, layers)\n",
    "\n",
    "# Update the optim totals for model F manually with values from ReDASH paper (manual fix for ArXiV version)\n",
    "# redash_optim_total['approx_relu'][1] = 433.0\n",
    "# redash_optim_total['conv2d'][1] = 2742.0\n",
    "# redash_optim_total['dense'][1] = 0.2\n",
    "# redash_optim_total['rescale'][1] = 455.0\n",
    "\n",
    "print(redash_optim_total)\n",
    "print(redash_eigen_total)\n",
    "print(redash_int32_eigen_total)\n",
    "\n",
    "# Define the three dataset categories to compare.\n",
    "datasets = [\"ReDASH Optimized\", \"ReDASH Optimized Eigen\", \"ReDASH Optimized Eigen Int32\"]\n",
    "n_datasets = len(datasets)\n",
    "n_models = len(model_names)\n",
    "bar_width = 0.25\n",
    "\n",
    "# x positions for model groups.\n",
    "indices = np.arange(n_models)\n",
    "\n",
    "# Create a mapping for layers to style using the pre-defined color_hatch_combinations.\n",
    "layer_style = {layer: color_hatch_combinations[i % len(color_hatch_combinations)]\n",
    "                for i, layer in enumerate(layers)}\n",
    "\n",
    "# Setup the figure.\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot bars for each dataset category.\n",
    "# Offsets: centered grouping per model.\n",
    "for i, dataset in enumerate(datasets):\n",
    "    pos = indices + (i - (n_datasets - 1) / 2) * bar_width\n",
    "    for j, m in enumerate(model_names):\n",
    "        if dataset == \"ReDASH Optimized\":\n",
    "            ser = pd.Series({layer: redash_optim_total.get(layer, [0]*n_models)[j] for layer in layers})\n",
    "        elif dataset == \"ReDASH Optimized Eigen\":\n",
    "            ser = pd.Series({layer: redash_eigen_total.get(layer, [0]*n_models)[j] for layer in layers})\n",
    "        elif dataset == \"ReDASH Optimized Eigen Int32\":\n",
    "            ser = pd.Series({layer: redash_int32_eigen_total.get(layer, [0]*n_models)[j] for layer in layers})\n",
    "        bottom = 0\n",
    "        for layer in layers:\n",
    "            val = ser[layer]\n",
    "            c, h = layer_style[layer]\n",
    "            ax.bar(pos[j], val, bar_width, bottom=bottom, color=c, hatch=h, edgecolor='black')\n",
    "            bottom += val\n",
    "\n",
    "# Set x-axis: one tick per model (using the center of grouped bars)\n",
    "ax.set_xticks(indices)\n",
    "# Replace model names with short labels: f and F.\n",
    "model_labels = {\"MODEL_F_GNNP_POOL_REPL\": \"f\", \"MODEL_F_MINIONN_POOL_REPL\": \"F\"}\n",
    "# ax.set_xticklabels([model_labels[m] for m in model_names])\n",
    "# ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Online runtime (ms)\")\n",
    "\n",
    "# Instead of placing model labels at the default bottom,\n",
    "# we remove the current ticks and set two x-axis labels.\n",
    "# 1. Bottom ticks for dataset categories (I, II, III) for each model.\n",
    "roman = [\"I\", \"I*\", \"I**\"]\n",
    "tick_positions = []\n",
    "tick_labels = []\n",
    "for x in indices:\n",
    "    for i in range(n_datasets):\n",
    "        tick_positions.append(x + (i - (n_datasets - 1)/2)*bar_width)\n",
    "        tick_labels.append(roman[i])\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(tick_labels)\n",
    "ax.set_xlabel(\"Setup\")\n",
    "\n",
    "# 2. Create a twin x-axis at the top for the model labels (f and F).\n",
    "ax_top = ax.twiny()\n",
    "ax_top.set_xlim(ax.get_xlim())\n",
    "ax_top.set_xticks(indices)\n",
    "ax_top.set_xticklabels([model_labels[m] for m in model_names])\n",
    "ax_top.xaxis.set_ticks_position('top')\n",
    "ax_top.xaxis.set_label_position('top')\n",
    "ax_top.set_xlabel(\"Model\")\n",
    "ax_top.set_zorder(-1)\n",
    "\n",
    "layer_label = {\n",
    "    'approx_relu': 'ReLU',\n",
    "    'conv2d': 'Conv2d',\n",
    "    'dense': 'Dense',\n",
    "    'rescale': 'Scaling'\n",
    "}\n",
    "\n",
    "# Create a combined legend for layers.\n",
    "legend_handles = [mpatches.Patch(facecolor=layer_style[layer][0],\n",
    "                                 hatch=layer_style[layer][1],\n",
    "                                 edgecolor='black',\n",
    "                                 label=layer_label.get(layer, layer))\n",
    "                  for layer in layers]\n",
    "ax.legend(handles=legend_handles, title=\"Layer\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.tight_layout()\n",
    "ax.grid(False)\n",
    "\n",
    "fig.savefig(\"model_benchmarks/data/vertical_combined_runtime_distribution_EigenInt32.pdf\", format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee4da9",
   "metadata": {},
   "source": [
    "## Ciphertext Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm_dict = {\n",
    "    3: [2,3,5],\n",
    "    4: [2,3,5,7],\n",
    "    5: [2,3,5,7,11],\n",
    "    6: [2,3,5,7,11,13],\n",
    "    7: [2,3,5,7,11,13,17],\n",
    "    8: [2,3,5,7,11,13,17,19]\n",
    "}\n",
    "\n",
    "mrs_dict = {\n",
    "    3: [32],\n",
    "    4: [26,3],\n",
    "    5: [54,4,3],\n",
    "    6: [60,125],\n",
    "    7: [86,7,36,5],\n",
    "    8: [92,7,6,125,4]\n",
    "}\n",
    "\n",
    "def redash_ciphertexts(k):\n",
    "    crt_base = cpm_dict[k]\n",
    "    crt_base[0], crt_base[-1] = crt_base[-1], crt_base[0]\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(1, k):\n",
    "        for j in range(i, k):\n",
    "            sum += crt_base[j]\n",
    "    return sum\n",
    "\n",
    "def dash_cipher_texts(k):\n",
    "    crt_base = cpm_dict[k]\n",
    "    mrs_base = mrs_dict[k]\n",
    "    t = len(mrs_base)\n",
    "\n",
    "    sum1 = 0\n",
    "    for i in range(0, k):\n",
    "        sum1 += crt_base[i]\n",
    "    sum1 *= t\n",
    "\n",
    "    sum2 = 0\n",
    "    for i in range(1, t):\n",
    "        sum2 += (mrs_base[i] + 2 * t * (k-1))\n",
    "    sum2 *= 2 * k\n",
    "    \n",
    "\n",
    "    sum3 = mrs_base[0]\n",
    "\n",
    "    base_change_projection_ciphertexts = 2 * (k-1)\n",
    "\n",
    "    return sum1 + sum2 + sum3 + base_change_projection_ciphertexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63864947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define k values corresponding to the data points\n",
    "k_values = list(range(3, 9))\n",
    "\n",
    "dash_data = [dash_cipher_texts(k) for k in k_values]\n",
    "redash_data = [redash_ciphertexts(k) for k in k_values]\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(k_values, redash_data, marker='o', linestyle='-', label=\"ReDASH\")\n",
    "plt.plot(k_values, dash_data, marker='*', linestyle='--', label=\"DASH\")\n",
    "\n",
    "plt.xlabel(\"RNS Size ($k$)\")\n",
    "plt.ylabel(\"Ciphertexts per Input\")\n",
    "plt.yscale('linear')  # set y-axis to a normal (linear) scale\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"micro_benchmarks/data/ciphertexts_per_input.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
